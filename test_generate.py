import os
import subprocess
import shutil
from transformers import T5Tokenizer, T5ForConditionalGeneration
import torch
from git import Repo

MODEL_DIR = "./output/commit_model"
TEST_REPO = "/tmp/test-repo"
device = torch.device("cpu")

# √âtape 1 : Cr√©er un d√©p√¥t temporaire
if os.path.exists(TEST_REPO):
    shutil.rmtree(TEST_REPO)
os.makedirs(TEST_REPO, exist_ok=True)

# √âtape 2 : Initialiser le d√©p√¥t Git et cr√©er un fichier
repo = Repo.init(TEST_REPO)
with open(os.path.join(TEST_REPO, "hello.py"), "w") as f:
    f.write("print('hello world')\n")

repo.git.add("hello.py")
repo.index.commit("Initial commit")

# √âtape 3 : Modifier le fichier
with open(os.path.join(TEST_REPO, "hello.py"), "a") as f:
     f.write("\n\ndef greet(name):\n    print(f\"Hello, {name}\")\n")

repo.git.add("hello.py")

# √âtape 4 : Charger le mod√®le
tokenizer = T5Tokenizer.from_pretrained(MODEL_DIR, legacy=True)
model = T5ForConditionalGeneration.from_pretrained(MODEL_DIR).to(device)

# √âtape 5 : G√©n√©rer le message de commit
diff = repo.git.diff('--cached', '--no-color')
diff_clean = "\n".join(line for line in diff.splitlines() if line.startswith('+') or line.startswith('-'))

if not diff_clean.strip():
    print("[AUCUN CHANGEMENT] Aucun diff d√©tect√©.")
else:
    prompt = "Generate a commit message for these changes:\n" + diff_clean
    input_ids = tokenizer(prompt, return_tensors='pt', max_length=512, truncation=True).input_ids.to(device)
    outputs = model.generate(input_ids, max_length=128, num_beams=4, early_stopping=True)
    message = tokenizer.decode(outputs[0], skip_special_tokens=True)

    print("\nüí¨ Message g√©n√©r√© :")
    print(message)